<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Basics of Web Scraping</title>
</head>
<body bgcolor="	#d8cdbb">
    <h1>Basics of Web Scraping</h1>
    <h2> What is Web Scraping?</h2>
    <hr size="3" noshade>
    <p><strong>Web Scraping:</strong>It means Automated Web Data Extraction. There are 
    two parts: <strong>A. Crawling:</strong>A web crawler or spider searches for content
    by following links and exploring & <strong>B. Scrapers:</strong> A Scrape 
    program does data extraction from web pages. </p>
    <p> However while Web Scraping the Ethics of Scraping must be maintained.</p>
    <h2>What is an API?</h2>
    <hr size="3" noshade>
    <p><strong>API stands for Application Programming Interface. </strong></p>
    <li> It is a software intermediary that allows two applications to talk to each 
        other. Each time you use an app like Facebook, send an instant message, 
        or check the weather on your phone, you're using an API.</li>
    <li>APIs are thus required to incorporate a third party functionality.</li>
    <li>API can be free or paid.</li>
    <li>Every API must have some form of documentation.</li>
    <li>API can be considered as a form of contract between the client and the server.
        Thus if a client makes an request in a specific format the server will 
        initiate a defined action. The common step is to make a http request to the 
        server. 
    </li>
    <h2> What are http requests?</h2>
    <hr size="3" noshade>
    <p><strong>http stands for hypertext transfer protocol</strong></p>
    <li>It specifies how requests and responses are to be formmatted ans transmitted.</li>
    <li>
        Websites contain a collection of files : the html code for web pages along 
        with other supplementary resources like images, videos , styles. These 
        files are stored in remote computers somewhere called Server. While surfing
        all we do is download these files on our computer and use our browser to 
        display the results properly. This is carried out by making a http request.
    </li>
    <li>
        The requests can be classified into 2 categories: <strong>A. GET & 
        B. POST</strong>
    </li>
    <h2>Working with certain APIs</h2>
    <hr size="3" noshade>
    <h3>Exchange Rate API</h3>
    
</body>
</html>